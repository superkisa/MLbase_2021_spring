{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <center><img src=\"images/header.png\" width=400></center> </td>\n",
    "    <td> <center><img src=\"images/header2.png\" width=400></center> </td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "<h1><center>Основы машинного обучения</center></h1>\n",
    "<hr>\n",
    "<h2><center>Методы обучения без учителя: Кластеризация (практика)</center></h2>\n",
    "<h3><center>Шестаков Андрей</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn-talk')\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "\n",
    "# Для кириллицы на графиках\n",
    "font = {'family': 'Verdana',\n",
    "        'weight': 'normal'}\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you are using colab\n",
    "# !mkdir ./data\n",
    "# !wget https://raw.githubusercontent.com/vadim0912/MLbase_2021_spring/l4/lecture04/data/diet.csv -O ./data/diet.csv\n",
    "# !wget https://raw.githubusercontent.com/vadim0912/MLbase_2021_spring/l4/lecture04/data/snsdata.csv -O ./data/snsdata.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Применение K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите [данные](https://github.com/brenden17/sklearnlab/blob/master/facebook/snsdata.csv) в которых содержится описание интересов профилей учеников старшей школы США."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gradyear</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>friends</th>\n",
       "      <th>basketball</th>\n",
       "      <th>football</th>\n",
       "      <th>soccer</th>\n",
       "      <th>softball</th>\n",
       "      <th>volleyball</th>\n",
       "      <th>swimming</th>\n",
       "      <th>...</th>\n",
       "      <th>blonde</th>\n",
       "      <th>mall</th>\n",
       "      <th>shopping</th>\n",
       "      <th>clothes</th>\n",
       "      <th>hollister</th>\n",
       "      <th>abercrombie</th>\n",
       "      <th>die</th>\n",
       "      <th>death</th>\n",
       "      <th>drunk</th>\n",
       "      <th>drugs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006</td>\n",
       "      <td>M</td>\n",
       "      <td>18.982</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>F</td>\n",
       "      <td>18.801</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006</td>\n",
       "      <td>M</td>\n",
       "      <td>18.335</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006</td>\n",
       "      <td>F</td>\n",
       "      <td>18.875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.995</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gradyear gender     age  friends  basketball  football  soccer  softball  \\\n",
       "0      2006      M  18.982        7           0         0       0         0   \n",
       "1      2006      F  18.801        0           0         1       0         0   \n",
       "2      2006      M  18.335       69           0         1       0         0   \n",
       "3      2006      F  18.875        0           0         0       0         0   \n",
       "4      2006    NaN  18.995       10           0         0       0         0   \n",
       "\n",
       "   volleyball  swimming  ...  blonde  mall  shopping  clothes  hollister  \\\n",
       "0           0         0  ...       0     0         0        0          0   \n",
       "1           0         0  ...       0     1         0        0          0   \n",
       "2           0         0  ...       0     0         0        0          0   \n",
       "3           0         0  ...       0     0         0        0          0   \n",
       "4           0         0  ...       0     0         2        0          0   \n",
       "\n",
       "   abercrombie  die  death  drunk  drugs  \n",
       "0            0    0      0      0      0  \n",
       "1            0    0      0      0      0  \n",
       "2            0    0      1      0      0  \n",
       "3            0    0      0      0      0  \n",
       "4            0    0      0      1      1  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sns = pd.read_csv('data/snsdata.csv', sep=',')\n",
    "df_sns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные устроены так: \n",
    "* Год выпуска\n",
    "* Пол\n",
    "* Возраст\n",
    "* Количество друзей\n",
    "* 36 ключевых слов, которые встречаются в профилe facebook (интересы, сообщества, встречи)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание\n",
    "\n",
    "* Удалите все признаки кроме 36 ключевых слов.\n",
    "* Нормализуйте данные - из каждого столбца вычтите его среднее значение и поделите на стандартное отклонение.\n",
    "* Используйте метод k-means чтобы выделить 9 кластеров\n",
    "* Попробуйте проинтерпретировать каждый кластер проанализировав полученные центройды (Некоторые кластеры могут быть очень большие и очень маленькие - плохо интерпретируются)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рационы питания в странах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите набор данных о пищевом рационе в разных странах мира `diet.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/diet.csv', sep=';').iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Countries</th>\n",
       "      <th>Energy (kcal/day)</th>\n",
       "      <th>Protein (g/day)</th>\n",
       "      <th>Fats (g/day)</th>\n",
       "      <th>Carbohydrates (g/day)</th>\n",
       "      <th>Animal Products + (kcal/day)</th>\n",
       "      <th>Animal Fats (kcal/day)</th>\n",
       "      <th>Bovine Meat (kcal/day)</th>\n",
       "      <th>Butter, Ghee (kcal/day)</th>\n",
       "      <th>Cheese (kcal/day)</th>\n",
       "      <th>...</th>\n",
       "      <th>Soyabean Oil (kcal/day)</th>\n",
       "      <th>Starchy Roots (kcal/day)</th>\n",
       "      <th>Sugar &amp; Sweeteners (kcal/day)</th>\n",
       "      <th>Sugar (Raw Equivalent) (kcal/day)</th>\n",
       "      <th>Sugar, Raw Equivalent (kcal/day)</th>\n",
       "      <th>Sugar, Refined Equiv (kcal/day)</th>\n",
       "      <th>Vegetable Oils (kcal/day)</th>\n",
       "      <th>Vegetables (kcal/day)</th>\n",
       "      <th>Wheat (kcal/day)</th>\n",
       "      <th>Wine (kcal/day)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albania</td>\n",
       "      <td>2860.0</td>\n",
       "      <td>96</td>\n",
       "      <td>86</td>\n",
       "      <td>425.50</td>\n",
       "      <td>813.0</td>\n",
       "      <td>49</td>\n",
       "      <td>62</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>193</td>\n",
       "      <td>187</td>\n",
       "      <td>191</td>\n",
       "      <td>187</td>\n",
       "      <td>174</td>\n",
       "      <td>94</td>\n",
       "      <td>1166</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>2980.0</td>\n",
       "      <td>94</td>\n",
       "      <td>100</td>\n",
       "      <td>426.00</td>\n",
       "      <td>823.0</td>\n",
       "      <td>72</td>\n",
       "      <td>342</td>\n",
       "      <td>28</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>100</td>\n",
       "      <td>406</td>\n",
       "      <td>337</td>\n",
       "      <td>405</td>\n",
       "      <td>337</td>\n",
       "      <td>311</td>\n",
       "      <td>51</td>\n",
       "      <td>914</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>3120.0</td>\n",
       "      <td>107</td>\n",
       "      <td>134</td>\n",
       "      <td>371.50</td>\n",
       "      <td>1033.0</td>\n",
       "      <td>124</td>\n",
       "      <td>142</td>\n",
       "      <td>62</td>\n",
       "      <td>107</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>87</td>\n",
       "      <td>423</td>\n",
       "      <td>407</td>\n",
       "      <td>415</td>\n",
       "      <td>407</td>\n",
       "      <td>435</td>\n",
       "      <td>67</td>\n",
       "      <td>559</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Austria</td>\n",
       "      <td>3740.0</td>\n",
       "      <td>111</td>\n",
       "      <td>162</td>\n",
       "      <td>459.50</td>\n",
       "      <td>1219.0</td>\n",
       "      <td>320</td>\n",
       "      <td>59</td>\n",
       "      <td>102</td>\n",
       "      <td>193</td>\n",
       "      <td>...</td>\n",
       "      <td>89</td>\n",
       "      <td>113</td>\n",
       "      <td>437</td>\n",
       "      <td>404</td>\n",
       "      <td>424</td>\n",
       "      <td>404</td>\n",
       "      <td>442</td>\n",
       "      <td>61</td>\n",
       "      <td>617</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>48</td>\n",
       "      <td>25</td>\n",
       "      <td>445.75</td>\n",
       "      <td>65.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>42</td>\n",
       "      <td>59</td>\n",
       "      <td>29</td>\n",
       "      <td>59</td>\n",
       "      <td>29</td>\n",
       "      <td>131</td>\n",
       "      <td>10</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Countries  Energy (kcal/day)  Protein (g/day)  Fats (g/day)  \\\n",
       "0     Albania             2860.0               96            86   \n",
       "1   Argentina             2980.0               94           100   \n",
       "2   Australia             3120.0              107           134   \n",
       "3     Austria             3740.0              111           162   \n",
       "4  Bangladesh             2200.0               48            25   \n",
       "\n",
       "   Carbohydrates (g/day)  Animal Products + (kcal/day)  \\\n",
       "0                 425.50                         813.0   \n",
       "1                 426.00                         823.0   \n",
       "2                 371.50                        1033.0   \n",
       "3                 459.50                        1219.0   \n",
       "4                 445.75                          65.0   \n",
       "\n",
       "   Animal Fats (kcal/day)  Bovine Meat (kcal/day)  Butter, Ghee (kcal/day)  \\\n",
       "0                      49                      62                       11   \n",
       "1                      72                     342                       28   \n",
       "2                     124                     142                       62   \n",
       "3                     320                      59                      102   \n",
       "4                       5                       5                        3   \n",
       "\n",
       "   Cheese (kcal/day)  ...  Soyabean Oil (kcal/day)  Starchy Roots (kcal/day)  \\\n",
       "0                 50  ...                        2                        57   \n",
       "1                 90  ...                       43                       100   \n",
       "2                107  ...                       17                        87   \n",
       "3                193  ...                       89                       113   \n",
       "4                  0  ...                       48                        42   \n",
       "\n",
       "   Sugar & Sweeteners (kcal/day)  Sugar (Raw Equivalent) (kcal/day)  \\\n",
       "0                            193                                187   \n",
       "1                            406                                337   \n",
       "2                            423                                407   \n",
       "3                            437                                404   \n",
       "4                             59                                 29   \n",
       "\n",
       "   Sugar, Raw Equivalent (kcal/day)  Sugar, Refined Equiv (kcal/day)  \\\n",
       "0                               191                              187   \n",
       "1                               405                              337   \n",
       "2                               415                              407   \n",
       "3                               424                              404   \n",
       "4                                59                               29   \n",
       "\n",
       "   Vegetable Oils (kcal/day)  Vegetables (kcal/day)  Wheat (kcal/day)  \\\n",
       "0                        174                     94              1166   \n",
       "1                        311                     51               914   \n",
       "2                        435                     67               559   \n",
       "3                        442                     61               617   \n",
       "4                        131                     10               180   \n",
       "\n",
       "   Wine (kcal/day)  \n",
       "0                6  \n",
       "1               59  \n",
       "2               39  \n",
       "3               55  \n",
       "4                0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Отнормируйте данные с помощью `RobustScaler` или `StandardScaler`\n",
    "2. Используйте метод K-средних. Выберите число кластеров с помощью критерия силуэта\n",
    "3. Найдите выборосы и проинтерпретируйте кластеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка `epsilon` для DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То что нам не нужно определять количество выходных кластеров в DBSCAN - это конечно хорошо, но как определить `min_pts` и `epsilon`?) Есть одна методика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем считать, что MinPts нам дан свыше (например MinPts = 2). Воспользуемся следующим способом оценки:\n",
    "\n",
    "* Нормализуем признаки, например с помощью `RobustScaler` или `StandartScaler`\n",
    "* Расчитаем расстояние до k=MinPts ближайшего соседа каждой точки (класс `NearestNeighbors` и метод `kneighbors`)\n",
    "* Отсортируем полученный массив и выведите его на график\n",
    "* По графику будет примерно понятно, сколько точек уйдет в шум, а сколько попадет в полноценный кластер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача про кластеризацию текстов (ДЗ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Рассмотрим коллекцию новостных сообщений за первую половину 2017 года. Про каждое новостное сообщение известны:\n",
    "* его заголовок и текст\n",
    "* дата его публикации\n",
    "* событие, о котором это новостное сообщение написано \n",
    "* его рубрика "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>event</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>В ПЕТЕРБУРГЕ ПРОШЕЛ МИТИНГ ПРОТИВ ПЕРЕДАЧИ ИС...</td>\n",
       "      <td>2017-01-10</td>\n",
       "      <td>Передача РПЦ Исаакиевского собора</td>\n",
       "      <td>Внутренняя политика РФ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenta.co, Москва, 14 января 2017 СИТУАЦИЯ С П...</td>\n",
       "      <td>2017-01-10</td>\n",
       "      <td>Передача РПЦ Исаакиевского собора</td>\n",
       "      <td>Внутренняя политика РФ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Аргументы и Факты (aif.ru), Москва, 14 января...</td>\n",
       "      <td>2017-01-10</td>\n",
       "      <td>Передача РПЦ Исаакиевского собора</td>\n",
       "      <td>Внутренняя политика РФ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google Новости ТОП, Москва, 14 января 2017 АК...</td>\n",
       "      <td>2017-01-10</td>\n",
       "      <td>Передача РПЦ Исаакиевского собора</td>\n",
       "      <td>Внутренняя политика РФ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Газета.Ru, Москва, 13 января 2017 В МОСКОВСКО...</td>\n",
       "      <td>2017-01-10</td>\n",
       "      <td>Передача РПЦ Исаакиевского собора</td>\n",
       "      <td>Внутренняя политика РФ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text        date  \\\n",
       "0   В ПЕТЕРБУРГЕ ПРОШЕЛ МИТИНГ ПРОТИВ ПЕРЕДАЧИ ИС...  2017-01-10   \n",
       "1   Lenta.co, Москва, 14 января 2017 СИТУАЦИЯ С П...  2017-01-10   \n",
       "2   Аргументы и Факты (aif.ru), Москва, 14 января...  2017-01-10   \n",
       "3   Google Новости ТОП, Москва, 14 января 2017 АК...  2017-01-10   \n",
       "4   Газета.Ru, Москва, 13 января 2017 В МОСКОВСКО...  2017-01-10   \n",
       "\n",
       "                                event                   class  \n",
       "0  Передача РПЦ Исаакиевского собора   Внутренняя политика РФ  \n",
       "1  Передача РПЦ Исаакиевского собора   Внутренняя политика РФ  \n",
       "2  Передача РПЦ Исаакиевского собора   Внутренняя политика РФ  \n",
       "3  Передача РПЦ Исаакиевского собора   Внутренняя политика РФ  \n",
       "4  Передача РПЦ Исаакиевского собора   Внутренняя политика РФ  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/news.csv', encoding='utf8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Важные мировые события                           403\n",
       "Внутренняя политика РФ                           364\n",
       "Внутренняя политика РФ: оппозиция                277\n",
       "Теракты                                          200\n",
       "Международные отношения                          153\n",
       "Спорт                                            102\n",
       "Спорт                                            100\n",
       "Внутренняя политика: культура                    100\n",
       "Проишествия  РФ                                  100\n",
       "Международные отношения: Криминальная хроника     82\n",
       "Технологии                                        49\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, 'class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем кластеризовать документы (каким-либо методом) и сравним полученное разбиение с данными рубликами с помощью ARI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стандартная предобработка текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Оставляем только кириллические символы\n",
    "regex = re.compile(u\"[А-Яа-я]+\")\n",
    "\n",
    "def words_only(text, regex=regex):\n",
    "    return \" \".join(regex.findall(text))\n",
    "\n",
    "\n",
    "df.text = df.text.str.lower()\n",
    "df.loc[:, 'text'] = df.text.apply(words_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/andrey.shestakov/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Удаляем стоп-слова\n",
    "mystopwords = stopwords.words('russian') + ['это', 'наш' , 'тыс', 'млн', 'млрд', u'также',  'т', 'д', '-', '-']\n",
    "\n",
    "def  remove_stopwords(text, mystopwords = mystopwords):\n",
    "    try:\n",
    "        return u\" \".join([token for token in text.split() if not token in mystopwords])\n",
    "    except:\n",
    "        return u\"\"\n",
    "    \n",
    "df.text = df.text.apply(remove_stopwords)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymystem3\n",
      "  Downloading pymystem3-0.2.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: requests in /Users/andrey.shestakov/opt/anaconda3/lib/python3.8/site-packages (from pymystem3) (2.24.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/andrey.shestakov/opt/anaconda3/lib/python3.8/site-packages (from requests->pymystem3) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/andrey.shestakov/opt/anaconda3/lib/python3.8/site-packages (from requests->pymystem3) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/andrey.shestakov/opt/anaconda3/lib/python3.8/site-packages (from requests->pymystem3) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/andrey.shestakov/opt/anaconda3/lib/python3.8/site-packages (from requests->pymystem3) (2020.6.20)\n",
      "Installing collected packages: pymystem3\n",
      "Successfully installed pymystem3-0.2.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pymystem3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pymystem3'"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from pymystem3 import Mystem\n",
    "\n",
    "\n",
    "# нормализуем текст\n",
    "m = Mystem()\n",
    "def lemmatize(text, mystem=m):\n",
    "    try:\n",
    "        return \"\".join(m.lemmatize(text)).strip()  \n",
    "    except:\n",
    "        return \" \"\n",
    "\n",
    "df.text = df.text.apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mystoplemmas = [u'который', u'прошлый', u'сей', u'свой', u'наш', u'мочь']\n",
    "\n",
    "# Еще кое-что удаляем\n",
    "def  remove_stoplemmas(text, mystoplemmas = mystoplemmas):\n",
    "    try:\n",
    "        return \" \".join([token for token in text.split() if not token in mystoplemmas])\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "df.text = df.text.apply(remove_stoplemmas)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вычисление сходства"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью `TfidfVectorizer` и `pairwise_distances` расчитайте косинусное расстояние между всеми парами документов к корпусе\n",
    "\n",
    "Запишите результат в переменную `S`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()\n",
    "texts = df.text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "sns.heatmap(data=S, cmap = 'Spectral').set(xticklabels=[],yticklabels=[])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы должны пронаблюдать, что между некоторыми текстами есть довольно выскокое сходство по содержанию слов. \n",
    "\n",
    "Попробуем их кластеризовать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN\n",
    "* Воспользуйтесь методикой оценки параметров для алгоритма DBSCAN. Используйте косинусную меру близости\n",
    "* Выделите кластеры. Для каждого кластера (кроме -1, если он будет) выведите несколько текстов и умозрительно определите его тематику\n",
    "* Оцените сходство с изначальными рубриками визуально (с помощью матрицы перемешивания) и с помощью ARI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_rand_score(true_label, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab(df.loc[:, 'class'], labels)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "livereveal": {
   "theme": "serif",
   "transition": "concave",
   "width": "1024px"
  },
  "nav_menu": {},
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "105px",
    "width": "253px"
   },
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "toc_position": {
   "height": "32px",
   "left": "9px",
   "right": "1379px",
   "top": "33px",
   "width": "212px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
