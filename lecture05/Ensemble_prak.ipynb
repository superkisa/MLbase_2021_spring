{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import auc, f1_score, accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from tqdm import tqdm_notebook\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.json') as data_file:    \n",
    "    data = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_num = np.array([len(i[\"ingredients\"]) for i in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine = []\n",
    "ingredients = []\n",
    "ingredients_num = []\n",
    "for i in data:\n",
    "    if len(i[\"ingredients\"]) < 50:\n",
    "        ingredients.append(\" \".join(i[\"ingredients\"]))\n",
    "        cuisine.append(i[\"cuisine\"])\n",
    "        ingredients_num.append(len(i[\"ingredients\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"cuisine\"] = cuisine\n",
    "df[\"ingridients\"] = ingredients\n",
    "df[\"ingredients_num\"] = ingredients_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.groupby(\"cuisine\")[\"ingredients_num\"].mean().reset_index()\n",
    "                                         .sort_values(\"ingredients_num\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "chart = sns.countplot(cuisine)\n",
    "ch = chart.set_xticklabels(chart.get_xticklabels(), rotation=65, horizontalalignment='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=10, max_df=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LE = LabelEncoder()\n",
    "labels = LE.fit_transform(cuisine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_test, ans):\n",
    "    print \"Accuracy ~\", np.round(accuracy_score(y_test, ans), 4)\n",
    "    print \"F1_score ~\", np.round(f1_score(y_test, ans, average=\"macro\"), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(solver='liblinear')\n",
    "LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_ans = LR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(y_test, lr_ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(n_estimators=100)\n",
    "RF.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_ans = RF.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(y_test, RF_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR.predict_proba(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_stack = RandomForestClassifier(n_estimators=100)\n",
    "RF_stack.fit(LR.predict_proba(X_train), y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_predict_proba = RF_stack.predict(LR.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_ans_stack = RF_stack.predict(np.hstack((X_test.toarray(), LR.predict_proba(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(y_test, RF_predict_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(y_test, RF_ans_stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cuisine\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine1 = \"russian\"\n",
    "cuisine2 = \"brazilian\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine1_df = df[df[\"cuisine\"] == cuisine1]\n",
    "cuisine2_df = df[df[\"cuisine\"] == cuisine2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.title(\"Ingridients number in {} cuisine\".format(cuisine1))\n",
    "sns.countplot(cuisine1_df[\"ingredients_num\"])\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.title(\"Ingridients number in {} cuisine\".format(cuisine2))\n",
    "sns.countplot(cuisine2_df[\"ingredients_num\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "fig = sns.kdeplot(cuisine1_df[\"ingredients_num\"], label = cuisine1)\n",
    "fig = sns.kdeplot(cuisine2_df[\"ingredients_num\"], label = cuisine2)        \n",
    "fig.set(xlabel=u'Количество ингридиентов', ylabel=u'Плотность')    \n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь было бы хорошо оценить, из скольки ингридентов в среднем состоят блюда каждой из кухонь. Так как данных в нашем датасете мало, то искать среднее не совсем правильно, лучше применить наши новые знания бутстрэпа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bootstrap_samples(data, n_samples):\n",
    "    \"\"\"Функция для генерации n_samples подвыборок с помощью бутстрэпа\"\"\"\n",
    "    indices = np.random.randint(0, len(data), (n_samples, len(data)))\n",
    "    samples = data[indices]\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_intervals(stat, alpha):\n",
    "    \"\"\"Функция для интервальной оценки\"\"\"\n",
    "    boundaries = np.percentile(stat, [100 * alpha / 2., 100 * (1 - alpha / 2.)])\n",
    "    return np.round(boundaries, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine1_ingridients = cuisine1_df[\"ingredients_num\"].values\n",
    "cuisine2_ingridients = cuisine2_df[\"ingredients_num\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine1_ingridients_scores = [np.mean(sample) \n",
    "                       for sample in get_bootstrap_samples(cuisine1_ingridients, 5000)]\n",
    "cuisine2_ingridients_scores = [np.mean(sample) \n",
    "                       for sample in get_bootstrap_samples(cuisine2_ingridients, 5000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"{} ingridients number:  mean interval\".format(cuisine1),  stat_intervals(cuisine1_ingridients_scores, 0.05)\n",
    "print \"{} ingridients number:  mean interval\".format(cuisine2),  stat_intervals(cuisine2_ingridients_scores, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"В итоге мы получили, что с 95% вероятностью среднее число ингридиентов в {} кухне будет лежать в промежутке между {r[0]} и {r[1]},  в то время как в {} в среднем от {b[0]} до {b[1]}\"\"\"\n",
    ".format(cuisine1, cuisine2, r=stat_intervals(cuisine1_ingridients_scores, 0.05), b=stat_intervals(cuisine2_ingridients_scores, 0.05)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Бэггинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier()\n",
    "DT.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_ans = DT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(y_test, DT_ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_dt_answer = [np.bincount(answer[:, i]).argmax() for i in range(answer.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(y_test, bagging_dt_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RSM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsm_dt_answer = [np.bincount(answer[:, i]).argmax() for i in range(answer.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(y_test, rsm_dt_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest():\n",
    "    \n",
    "    def __init__(self, n_estimators=20, max_depth=None, random_state=42):\n",
    "            \n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.trees_ = [] # \n",
    "        self.features_idx = []\n",
    "        self.random_state = random_state\n",
    "\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        for t in tqdm_notebook(range(self.n_estimators)):               \n",
    "            # выбираем базовый алгоритм - дерево\n",
    "            \n",
    "            # сэмплируем объекты\n",
    "            \n",
    "            # сэмплируем признаки\n",
    "\n",
    "            # обучаем\n",
    "\n",
    "            # добавляем алгоритм к ансамблю\n",
    "\n",
    "            # добавляем признаки\n",
    "\n",
    "                   \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        answer = np.zeros((len(self.trees_), X.shape[0]), dtype=int)\n",
    "        # добавляем прогнозы деревьев\n",
    "        for t in range(len(self.trees_)):\n",
    "            answer[t] = \n",
    "            \n",
    "        return np.array([np.bincount(answer[:, i]).argmax() for i in range(answer.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForest()\n",
    "RF.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_ans = RF.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(y_test, RF_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_stack.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_stack.feature_importances_[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(RF_stack.feature_importances_)[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(RF_stack.feature_importances_)[-20:] >= 1489"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ограничим датасет для быстроты подбора параметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "british          804\n",
    "filipino         755\n",
    "irish            667\n",
    "jamaican         526\n",
    "russian          489\n",
    "brazilian        466"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutted_labels = LE.transform([\"british\", \"filipino\", \"irish\", \"jamaican\", \"russian\", \"brazilian\", \"spanish\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = []\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] in cutted_labels:\n",
    "        idx.append(i)\n",
    "idx = np.array(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = X[idx], labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC = RandomForestClassifier(n_estimators=100, random_state=42, oob_score=True)\n",
    "temp_train_acc = []\n",
    "temp_test_acc = []\n",
    "temp_train_f1 = []\n",
    "temp_test_f1 = []\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    RFC.fit(X_train, y_train)\n",
    "    temp_train_acc.append(accuracy_score(RFC.predict(X_train), y_train))\n",
    "    temp_train_f1.append(f1_score(RFC.predict(X_train), y_train, average=\"macro\"))\n",
    "    temp_test_acc.append(accuracy_score(RFC.predict(X_test), y_test))\n",
    "    temp_test_f1.append(f1_score(RFC.predict(X_test), y_test, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"f1_score is\", np.round(np.mean(temp_test_f1), 5)\n",
    "print \"accuracy is\", np.round(np.mean(temp_test_acc), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(test_metric_acc, train_metric_acc, test_metric_f1, train_metric_f1, grid, xlabel='X'):\n",
    "\n",
    "    train_acc, test_acc = np.asarray(train_metric_acc), np.asarray(test_metric_acc)\n",
    "    train_f1, test_f1 = np.asarray(train_metric_f1), np.asarray(test_metric_f1)\n",
    "    print \"Best accuracy_score on CV is {:.4f} with {}\".format(max(test_acc.mean(axis=1)), \n",
    "                                                    grid[np.argmax(test_acc.mean(axis=1))]), xlabel\n",
    "    plt.style.use('ggplot')\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.plot(grid, test_acc.mean(axis=1), label=\"test\")\n",
    "    plt.plot(grid, train_acc.mean(axis=1), label=\"train\")\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    print \"Best f1_score on CV is {:.4f} with {}\".format(max(test_f1.mean(axis=1)), \n",
    "                                                    grid[np.argmax(test_f1.mean(axis=1))]), xlabel\n",
    "    \n",
    "    plt.style.use('ggplot')\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.title(\"F1_score\")\n",
    "    plt.plot(grid, test_f1.mean(axis=1), label=\"test\")\n",
    "    plt.plot(grid, train_f1.mean(axis=1), label=\"train\")\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV(RFC, X, y):\n",
    "\n",
    "    temp_train_acc = []\n",
    "    temp_test_acc = []\n",
    "    temp_train_f1 = []\n",
    "    temp_test_f1 = []\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        RFC.fit(X_train, y_train)\n",
    "        train_ans = RFC.predict(X_train)\n",
    "        test_ans = RFC.predict(X_test)\n",
    "        temp_train_acc.append(accuracy_score(y_train, train_ans))\n",
    "        temp_train_f1.append(f1_score(y_train, train_ans, average=\"macro\"))\n",
    "        temp_test_acc.append(accuracy_score(y_test, test_ans))\n",
    "        temp_test_f1.append(f1_score(y_test, test_ans, average=\"macro\"))\n",
    "    \n",
    "    return temp_train_acc, temp_test_acc, temp_train_f1, temp_test_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Количество деревьев в ансамбле"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = []\n",
    "test_acc = []\n",
    "train_f1 = []\n",
    "test_f1 = []\n",
    "trees_grid = [5, 10, 15, 20, 30, 50, 75, 100]\n",
    "\n",
    "for ntrees in tqdm_notebook(trees_grid):\n",
    "    RFC = RandomForestClassifier(n_estimators=ntrees, random_state=42)\n",
    "    temp_train_acc, temp_test_acc, temp_train_f1, temp_test_f1 = CV(RFC, X, y)\n",
    "    train_acc.append(temp_train_acc)\n",
    "    test_acc.append(temp_test_acc)\n",
    "    train_f1.append(temp_train_f1)\n",
    "    test_f1.append(temp_test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(test_acc, train_acc, test_f1, train_f1, trees_grid, \"trees number\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Глубина леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "train_f1 = []\n",
    "test_f1 = []\n",
    "max_depth_grid = [5, 10, 15, 20, 30, 50, 100, 150]\n",
    "\n",
    "for max_depth in tqdm_notebook(max_depth_grid):\n",
    "    RFC = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=max_depth)\n",
    "    temp_train_acc, temp_test_acc, temp_train_f1, temp_test_f1 = CV(RFC, X, y)\n",
    "    train_acc.append(temp_train_acc)\n",
    "    test_acc.append(temp_test_acc)\n",
    "    train_f1.append(temp_train_f1)\n",
    "    test_f1.append(temp_test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(test_acc, train_acc, test_f1, train_f1, max_depth_grid, \"max_depth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAX_FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### По умолчанию он равен sqrt(n) в задачах классификации и n/3 в задачах регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "train_f1 = []\n",
    "test_f1 = []\n",
    "max_features_grid = [5, 10, 15, 20, 38, 50, 100, 500, 1000]\n",
    "\n",
    "for max_features in tqdm_notebook(max_features_grid):\n",
    "    RFC = RandomForestClassifier(n_estimators=100, random_state=42, max_features=max_features)\n",
    "    temp_train_acc, temp_test_acc, temp_train_f1, temp_test_f1 = CV(RFC, X, y)\n",
    "    train_acc.append(temp_train_acc)\n",
    "    test_acc.append(temp_test_acc)\n",
    "    train_f1.append(temp_train_f1)\n",
    "    test_f1.append(temp_test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(test_acc, train_acc, test_f1, train_f1, max_features_grid, \"max_features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIN SAMPLES LEAF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По классике, в задачах регрессии рекомендуется использовать значение 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "train_f1 = []\n",
    "test_f1 = []\n",
    "min_samples_leaf_grid = [1, 3, 5, 7, 10, 15, 20, 25]\n",
    "\n",
    "for min_samples_leaf in tqdm_notebook(min_samples_leaf_grid):\n",
    "    RFC = RandomForestClassifier(n_estimators=100, random_state=42, min_samples_leaf=min_samples_leaf)\n",
    "    temp_train_acc, temp_test_acc, temp_train_f1, temp_test_f1 = CV(RFC, X, y)\n",
    "    train_acc.append(temp_train_acc)\n",
    "    test_acc.append(temp_test_acc)\n",
    "    train_f1.append(temp_train_f1)\n",
    "    test_f1.append(temp_test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(test_acc, train_acc, test_f1, train_f1, min_samples_leaf_grid, \"min_samples_leaf_grid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_features': [1, 5, 10, 15, 20, 38, 50], \n",
    "              'min_samples_leaf': [1, 3, 5, 7],\n",
    "              'max_depth': [5, 10, 15, 20, 30, 50]}\n",
    "rfc = RandomForestClassifier(n_estimators=10, random_state=42, \n",
    "                             n_jobs=18, oob_score=True)\n",
    "gcv = GridSearchCV(rfc, parameters, n_jobs=18, cv=skf, verbose=1)\n",
    "gcv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Градиентный Бустинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Для простоты рассмотрим регрессию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = pd.read_csv(\"winequality-red.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wine.values[:, :-1]\n",
    "y = wine.values[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(wine.values[:, :-1], wine.values[:, -1], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$MSE(y, p) = \\frac{1}{n} (y-p)^T(y-p) = \\frac{1}{n} \\sum\\limits_{i=1}^n(y_i - p_i)^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\nabla MSE - ?$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый следующий алгоритм тоже будем настраивать на остатки предыдущих"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим, что остатки могут быть найдены как антиградиент функции потерь по ответу модели, посчитанный в точке ответа уже построенной композиции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientBoosting():\n",
    "    \n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=-1, random_state=42):\n",
    "            \n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.learning_rate = learning_rate\n",
    "        self.initialization = lambda y: np.mean(y) * np.ones(len(y))\n",
    "        self.loss_by_iter = [] # функция потерь на каждой итерации\n",
    "        self.trees_ = []\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def mse_grad(self, y, p):\n",
    "        # написать градиент\n",
    "        return \n",
    "\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        b = self.initialization(y)\n",
    "        prediction = b.copy()\n",
    "        for t in tqdm_notebook(range(self.n_estimators)):               \n",
    "            # считаем - антиградиент\n",
    "            resid = \n",
    "            # выбираем базовый алгоритм\n",
    "            tree = \n",
    "            # обучаемся на векторе антиградиента\n",
    "            tree.fit\n",
    "            # делаем предикт и добавляем алгоритм к ансамблю\n",
    "            b = tree\n",
    "            #добавляем дерево в ансамбль\n",
    "            self.trees_\n",
    "            # обновляем текущее приближение (lr * b)\n",
    "            prediction +=\n",
    "            \n",
    "            # обновляем лосс на обучении (опционально)\n",
    "            self.loss_by_iter\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # сначала инициализируем прогноз на тестовой выборке – \n",
    "        # это просто вектор из средних значений ответов на обучении\n",
    "        pred = \n",
    "        # добавляем прогнозы деревьев * lr\n",
    "        for t in range(self.n_estimators):\n",
    "            pred +=\n",
    "            \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = GradientBoosting(n_estimators=500, learning_rate=0.01, max_depth=None)\n",
    "tree.fit(X_train, y_train)\n",
    "mse(y_test, tree.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train, y_train)\n",
    "mse(y_test, tree.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = GradientBoosting(n_estimators=500, learning_rate=1., max_depth=None)\n",
    "tree.fit(X_train, y_train)\n",
    "mse(y_test, tree.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StohasticGradientBoosting():\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = GradientBoosting(n_estimators=500, learning_rate=0.9, max_depth=None)\n",
    "tree.fit(X_train, y_train)\n",
    "mse(y_test, tree.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "\n",
    "LGBM = LGBMRegressor(n_estimators=500)\n",
    "LGBM.fit(X_train, y_train.ravel())\n",
    "LGBM_ans = LGBM.predict(X_test)\n",
    "mse(y_test, LGBM_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(test_metric_mse, train_metric_mse, grid, xlabel='X'):\n",
    "\n",
    "    train_mse, test_mse = np.asarray(train_metric_mse), np.asarray(test_metric_mse)\n",
    "    print \"Best MSE on CV is {:.4f} with {}\".format(min(test_mse.mean(axis=1)), \n",
    "                                                    grid[np.argmin(test_mse.mean(axis=1))]), xlabel\n",
    "    plt.style.use('ggplot')\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.title(\"MSE\")\n",
    "    plt.plot(grid, test_mse.mean(axis=1), label=\"test\")\n",
    "    plt.plot(grid, train_mse.mean(axis=1), label=\"train\")\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Параметры Градиентного бустинга"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "train_mse = []\n",
    "test_mse = []\n",
    "learning_rates = [0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1.]\n",
    "\n",
    "for lr in tqdm_notebook(learning_rates):\n",
    "    LGBM = LGBMRegressor(learning_rate=lr)\n",
    "    temp_train_mse = []\n",
    "    temp_test_mse = []\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        LGBM.fit(X_train, y_train)\n",
    "        temp_train_mse.append(mse(LGBM.predict(X_train), y_train))\n",
    "        temp_test_mse.append(mse(LGBM.predict(X_test), y_test))\n",
    "    train_mse.append(temp_train_mse)\n",
    "    test_mse.append(temp_test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(test_mse, train_mse, learning_rates, \"learning rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "train_mse = []\n",
    "test_mse = []\n",
    "n_estimators = [1, 2, 4, 8, 16, 32, 64, 100, 200]\n",
    "\n",
    "for n in tqdm_notebook(n_estimators):\n",
    "    LGBM = LGBMRegressor(n_estimators=n)\n",
    "    temp_train_mse = []\n",
    "    temp_test_mse = []\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        LGBM.fit(X_train, y_train)\n",
    "        temp_train_mse.append(mse(LGBM.predict(X_train), y_train))\n",
    "        temp_test_mse.append(mse(LGBM.predict(X_test), y_test))\n",
    "    train_mse.append(temp_train_mse)\n",
    "    test_mse.append(temp_test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(test_mse, train_mse, n_estimators, \"n_estimators\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
