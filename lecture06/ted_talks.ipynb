{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#TED-Talks\" data-toc-modified-id=\"TED-Talks-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>TED Talks</a></span></li><li><span><a href=\"#Токенизация\" data-toc-modified-id=\"Токенизация-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Токенизация</a></span></li><li><span><a href=\"#Распределение-слов-по-частоте,-стоп-слова\" data-toc-modified-id=\"Распределение-слов-по-частоте,-стоп-слова-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Распределение слов по частоте, стоп слова</a></span></li><li><span><a href=\"#Приведение-к-нормальной-форме\" data-toc-modified-id=\"Приведение-к-нормальной-форме-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Приведение к нормальной форме</a></span></li><li><span><a href=\"#Выделение-коллокаций\" data-toc-modified-id=\"Выделение-коллокаций-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Выделение коллокаций</a></span></li><li><span><a href=\"#TF-IDF\" data-toc-modified-id=\"TF-IDF-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>TF-IDF</a></span><ul class=\"toc-item\"><li><span><a href=\"#поиск-похожих\" data-toc-modified-id=\"поиск-похожих-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>поиск похожих</a></span></li><li><span><a href=\"#выделение-ключевых-слов\" data-toc-modified-id=\"выделение-ключевых-слов-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>выделение ключевых слов</a></span></li></ul></li><li><span><a href=\"#Word2Vec\" data-toc-modified-id=\"Word2Vec-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Word2Vec</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sentence-Embeddings\" data-toc-modified-id=\"Sentence-Embeddings-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Sentence Embeddings</a></span></li></ul></li><li><span><a href=\"#Topic-Modeling\" data-toc-modified-id=\"Topic-Modeling-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Topic Modeling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Поиск-похожих-документов\" data-toc-modified-id=\"Поиск-похожих-документов-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>Поиск похожих документов</a></span></li><li><span><a href=\"#Краткое-описание-документов-(суммаризация)\" data-toc-modified-id=\"Краткое-описание-документов-(суммаризация)-8.2\"><span class=\"toc-item-num\">8.2&nbsp;&nbsp;</span>Краткое описание документов (суммаризация)</a></span></li><li><span><a href=\"#Визуализация-тематической-модели\" data-toc-modified-id=\"Визуализация-тематической-модели-8.3\"><span class=\"toc-item-num\">8.3&nbsp;&nbsp;</span>Визуализация тематической модели</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment if you are using colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:49:25.378145Z",
     "start_time": "2021-04-14T09:49:25.374842Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install razdel==0.5\n",
    "# !pip install pyLDAvis==2.1.2\n",
    "# !pip install pymorphy2==0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:49:29.308848Z",
     "start_time": "2021-04-14T09:49:25.381186Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import razdel\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import pymorphy2\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import plotly\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "from IPython.display import YouTubeVideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:49:29.316553Z",
     "start_time": "2021-04-14T09:49:29.311194Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "TOKEN_PATTERN = \"[а-яё]+\"\n",
    "\n",
    "DATA_PATH = './data/ted_talks.csv.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment if you are using colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:49:29.324755Z",
     "start_time": "2021-04-14T09:49:29.320240Z"
    }
   },
   "outputs": [],
   "source": [
    "# !mkdir ./data\n",
    "# !wget https://raw.githubusercontent.com/vadim0912/MLbase_2021_spring/master/lecture06/data/ted_talks.csv.gz -O $DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TED Talks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:49:29.904956Z",
     "start_time": "2021-04-14T09:49:29.327805Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:49:29.910184Z",
     "start_time": "2021-04-14T09:49:29.906713Z"
    }
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:49:30.052546Z",
     "start_time": "2021-04-14T09:49:29.911970Z"
    }
   },
   "outputs": [],
   "source": [
    "YouTubeVideo(\"ww9ClmCWBr0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:49:30.568482Z",
     "start_time": "2021-04-14T09:49:30.054632Z"
    }
   },
   "outputs": [],
   "source": [
    "df.text.str.len().hist(bins=200);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:49:31.031403Z",
     "start_time": "2021-04-14T09:49:30.571071Z"
    }
   },
   "outputs": [],
   "source": [
    "min_talk_len = 750\n",
    "\n",
    "df = df[df.text.str.len() >= min_talk_len].reset_index(drop=True)\n",
    "\n",
    "df.text.str.len().hist(bins=200);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:49:31.036888Z",
     "start_time": "2021-04-14T09:49:31.033303Z"
    }
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:49:31.041234Z",
     "start_time": "2021-04-14T09:49:31.038892Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = df.text.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:49:31.046648Z",
     "start_time": "2021-04-14T09:49:31.043444Z"
    }
   },
   "outputs": [],
   "source": [
    "sentence = \"Как же так?! Олег... Мы же в 18.00 договаривались встретиться:(\"\n",
    "\n",
    "print(sentence.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:49:31.052395Z",
     "start_time": "2021-04-14T09:49:31.048914Z"
    }
   },
   "outputs": [],
   "source": [
    "print(re.findall(\"[а-яА-ЯёЁ]+\", sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:49:31.057610Z",
     "start_time": "2021-04-14T09:49:31.054489Z"
    }
   },
   "outputs": [],
   "source": [
    "print(re.split(r\"[-\\s.,;!?]+\", sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:49:31.063146Z",
     "start_time": "2021-04-14T09:49:31.059549Z"
    }
   },
   "outputs": [],
   "source": [
    "print([token.text for token in razdel.tokenize(sentence)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:49:31.068217Z",
     "start_time": "2021-04-14T09:49:31.065263Z"
    }
   },
   "outputs": [],
   "source": [
    "print(nltk.tokenize.casual_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:49:31.074506Z",
     "start_time": "2021-04-14T09:49:31.070300Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:49:32.128878Z",
     "start_time": "2021-04-14T09:49:31.076386Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return re.findall(TOKEN_PATTERN, text.lower())\n",
    "\n",
    "docs = [tokenize(text) for text in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:49:32.144659Z",
     "start_time": "2021-04-14T09:49:32.131240Z"
    }
   },
   "outputs": [],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Распределение слов по частоте, стоп слова"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте словарь `слово` -> `количество вхождений в корпус`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:49:33.014221Z",
     "start_time": "2021-04-14T09:49:32.147596Z"
    }
   },
   "outputs": [],
   "source": [
    "occurence = Counter([token for doc in docs for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:49:33.023567Z",
     "start_time": "2021-04-14T09:49:33.016609Z"
    }
   },
   "outputs": [],
   "source": [
    "len(occurence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T13:57:09.967303Z",
     "start_time": "2020-10-31T13:57:09.956743Z"
    }
   },
   "source": [
    "в словаре больше 150 тыс. слов, хотя в литературном русском около 150 тыс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:49:33.069061Z",
     "start_time": "2021-04-14T09:49:33.026110Z"
    }
   },
   "outputs": [],
   "source": [
    "occurence.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самые частые слова относятся к служебным частям речи и несут мало полезной информации. Их можно отбрасывать с помощью подготовленных списков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:49:33.077860Z",
     "start_time": "2021-04-14T09:49:33.072281Z"
    }
   },
   "outputs": [],
   "source": [
    "stopword_set = set(nltk.corpus.stopwords.words('russian'))\n",
    "# stopword_set = stopword_set.union({'это', 'который', 'весь', 'наш', 'свой', 'ещё', 'её', 'ваш', 'также', 'итак'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:49:33.088862Z",
     "start_time": "2021-04-14T09:49:33.080834Z"
    }
   },
   "outputs": [],
   "source": [
    "stopword_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:49:33.890487Z",
     "start_time": "2021-04-14T09:49:33.092229Z"
    }
   },
   "outputs": [],
   "source": [
    "max_rank = 40_000\n",
    "\n",
    "counts = [count for _, count in occurence.most_common()[:max_rank]]\n",
    "\n",
    "plt.plot(range(1, len(counts) + 1), counts)\n",
    "plt.title('log-log scale', fontsize=18)\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel('rank', fontsize=16)\n",
    "plt.ylabel('count', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Приведение к нормальной форме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:49:34.050925Z",
     "start_time": "2021-04-14T09:49:33.892541Z"
    }
   },
   "outputs": [],
   "source": [
    "sorted_tokens = sorted(occurence.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:49:34.070040Z",
     "start_time": "2021-04-14T09:49:34.053938Z"
    }
   },
   "outputs": [],
   "source": [
    "sorted_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "в словаре встречаются разные формы одного и того же слова:\n",
    "* 'аббревиатур',\n",
    "* 'аббревиатура',\n",
    "* 'аббревиатуре',\n",
    "* 'аббревиатурой',\n",
    "* 'аббревиатуру',\n",
    "* 'аббревиатуры'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:49:34.075841Z",
     "start_time": "2021-04-14T09:49:34.073019Z"
    }
   },
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.SnowballStemmer('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:49:34.082495Z",
     "start_time": "2021-04-14T09:49:34.078670Z"
    }
   },
   "outputs": [],
   "source": [
    "words = [\n",
    "    'аббревиатур',\n",
    "    'аббревиатура',\n",
    "    'аббревиатуре',\n",
    "    'аббревиатурой',\n",
    "    'аббревиатуру',\n",
    "    'аббревиатуры',\n",
    "    'человек',\n",
    "    'люди',\n",
    "    'людьми'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:49:34.090015Z",
     "start_time": "2021-04-14T09:49:34.084355Z"
    }
   },
   "outputs": [],
   "source": [
    "[stemmer.stem(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:49:34.168047Z",
     "start_time": "2021-04-14T09:49:34.092054Z"
    }
   },
   "outputs": [],
   "source": [
    "lemmatizer = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:49:34.178985Z",
     "start_time": "2021-04-14T09:49:34.171481Z"
    }
   },
   "outputs": [],
   "source": [
    "lemmatizer.parse('стекло')[0].normal_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:49:34.188081Z",
     "start_time": "2021-04-14T09:49:34.181286Z"
    }
   },
   "outputs": [],
   "source": [
    "[lemmatizer.parse(word)[0].normal_form for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:49:34.195989Z",
     "start_time": "2021-04-14T09:49:34.190608Z"
    }
   },
   "outputs": [],
   "source": [
    "lemmatizer.word_is_known('хендай')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:49:34.206553Z",
     "start_time": "2021-04-14T09:49:34.198684Z"
    }
   },
   "outputs": [],
   "source": [
    "lemmatizer.parse('хендай')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:50:55.403660Z",
     "start_time": "2021-04-14T09:49:34.209478Z"
    }
   },
   "outputs": [],
   "source": [
    "lemmatizer_cache = {}\n",
    "\n",
    "def lemmatize(token):\n",
    "    if lemmatizer.word_is_known(token):\n",
    "        if token not in lemmatizer_cache:\n",
    "            lemmatizer_cache[token] = lemmatizer.parse(token)[0].normal_form\n",
    "        return lemmatizer_cache[token]\n",
    "    return token\n",
    "\n",
    "lemmatized_docs = [[lemmatize(token) for token in text] for text in tqdm_notebook(docs)]\n",
    "\n",
    "cleared_docs = [[token for token in text if token not in stopword_set] for text in lemmatized_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:50:55.436949Z",
     "start_time": "2021-04-14T09:50:55.412384Z"
    }
   },
   "outputs": [],
   "source": [
    "cleared_docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во сколько раз уменьшился словарь после лемматизации?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:50:55.607840Z",
     "start_time": "2021-04-14T09:50:55.439505Z"
    }
   },
   "outputs": [],
   "source": [
    "len({token for text in cleared_docs for token in text})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выделение коллокаций\n",
    "\n",
    "Посчитайте, сколько раз пары слов встречались вместе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:50:57.535907Z",
     "start_time": "2021-04-14T09:50:55.610037Z"
    }
   },
   "outputs": [],
   "source": [
    "cooccurence = Counter([(doc[i], doc[i + 1]) for doc in docs for i in range(len(doc) - 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:50:57.710005Z",
     "start_time": "2021-04-14T09:50:57.537942Z"
    }
   },
   "outputs": [],
   "source": [
    "cooccurence.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "PMI(x,y) = \\log\\frac{p\\left(x,y\\right)}{p\\left(x\\right)p\\left(y\\right)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "p(w_i) \\sim \\frac{\\text{count}\\left(w_i\\right)}{\\displaystyle\\sum_{j=1}^n \\text{count}\\left( w_j \\right)} = \\frac{\\text{count}\\left(w_i\\right)}{N}\n",
    "$$\n",
    "\n",
    "$$\n",
    "PMI(w_1, w_2) \\sim \\log\\left(\\frac{N \\cdot \\text{count}\\left(w_1, w_2\\right)}{\\text{count}\\left(w_1\\right) \\text{count}\\left(w_2\\right) }\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T18:51:18.654645Z",
     "start_time": "2020-11-02T18:51:18.608034Z"
    }
   },
   "source": [
    "постройте словарь, в котором парам слов соответствует значения pmi\n",
    "\n",
    "добавляйте в словарь только те пары слов, которые встретились в корпусе хотя бы `min_cooccur` раз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:50:57.880679Z",
     "start_time": "2021-04-14T09:50:57.711903Z"
    }
   },
   "outputs": [],
   "source": [
    "cooccurence.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:50:57.915719Z",
     "start_time": "2021-04-14T09:50:57.883964Z"
    }
   },
   "outputs": [],
   "source": [
    "occurence.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:50:57.923932Z",
     "start_time": "2021-04-14T09:50:57.917961Z"
    }
   },
   "outputs": [],
   "source": [
    "N = sum(occurence.values())\n",
    "\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:50:58.504551Z",
     "start_time": "2021-04-14T09:50:57.927040Z"
    }
   },
   "outputs": [],
   "source": [
    "min_cooccur = 5\n",
    "\n",
    "pmi = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:50:58.699317Z",
     "start_time": "2021-04-14T09:50:58.506711Z"
    }
   },
   "outputs": [],
   "source": [
    "pmi.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "если хочется автоматически выделять коллокации для извлечения признаков: [gensim.models.phrases.{Phrases, Phraser}](https://www.machinelearningplus.com/nlp/gensim-tutorial/#10howtocreatebigramsandtrigramsusingphrasermodels)\n",
    "\n",
    "```python\n",
    "phrases = (bows, min_count=30, progress_per=500)\n",
    "\n",
    "bigram = gensim.models.phrases.Phraser(phrases)\n",
    "\n",
    "bigram[bows[0]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## поиск похожих"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:50:59.546613Z",
     "start_time": "2021-04-14T09:50:58.701195Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    tokenizer=lambda x: x, lowercase=False, max_df=0.8, min_df=2, norm='l2'\n",
    ").fit(cleared_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "получите tf-idf векторы документов, посчитайте cosine similarity каждого документа с каждым"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:51:00.711890Z",
     "start_time": "2021-04-14T09:50:59.549518Z"
    }
   },
   "outputs": [],
   "source": [
    "docs_tf_idf = vectorizer.transform(cleared_docs).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:51:01.748167Z",
     "start_time": "2021-04-14T09:51:00.713745Z"
    }
   },
   "outputs": [],
   "source": [
    "similarities = docs_tf_idf @ docs_tf_idf.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:51:02.351918Z",
     "start_time": "2021-04-14T09:51:01.750738Z"
    }
   },
   "outputs": [],
   "source": [
    "def similar_pairs_from_matrix(similarity_matrix, threshold):\n",
    "    return [\n",
    "        ((i, j), similarities[i, j])\n",
    "        for i in range(similarities.shape[0]) for j in range(similarities.shape[1]) \n",
    "        if j > i  and similarities[i, j] > threshold\n",
    "    ]\n",
    "\n",
    "\n",
    "similar_pairs = similar_pairs_from_matrix(similarities, threshold=0.7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:51:02.358629Z",
     "start_time": "2021-04-14T09:51:02.354053Z"
    }
   },
   "outputs": [],
   "source": [
    "similar_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:51:02.364522Z",
     "start_time": "2021-04-14T09:51:02.361018Z"
    }
   },
   "outputs": [],
   "source": [
    "similar_pairs = sorted(similar_pairs, key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:51:02.369947Z",
     "start_time": "2021-04-14T09:51:02.366772Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_talks(talk_ids, text_chunk=1024):\n",
    "\n",
    "    for talk_id in talk_ids:\n",
    "        record = df.loc[talk_id]\n",
    "\n",
    "        print(record.talk)\n",
    "        print('-' * 100)\n",
    "        print(record.text[:text_chunk])\n",
    "        print('#' * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:51:02.408519Z",
     "start_time": "2021-04-14T09:51:02.371885Z"
    }
   },
   "outputs": [],
   "source": [
    "for pair, score in similar_pairs:\n",
    "    print(\"*\" * 10)\n",
    "    print(f\"{score:.2f}\")\n",
    "    print(\"*\" * 10)\n",
    "    print_talks(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## выделение ключевых слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:51:02.413345Z",
     "start_time": "2021-04-14T09:51:02.410704Z"
    }
   },
   "outputs": [],
   "source": [
    "top_k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:51:02.418341Z",
     "start_time": "2021-04-14T09:51:02.415737Z"
    }
   },
   "outputs": [],
   "source": [
    "doc_ids = [pair[0] for pair, threshold in similar_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:51:02.457238Z",
     "start_time": "2021-04-14T09:51:02.420560Z"
    }
   },
   "outputs": [],
   "source": [
    "features = np.array(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:51:02.473154Z",
     "start_time": "2021-04-14T09:51:02.460375Z"
    }
   },
   "outputs": [],
   "source": [
    "[\n",
    "    features[docs_tf_idf[doc_id].argsort()[::-1][:top_k]]\n",
    "    for doc_id in doc_ids\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:52:14.881972Z",
     "start_time": "2021-04-14T09:51:02.475995Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_sentence_dataset(documents):\n",
    "    tokenized_sentences = []\n",
    "    for document in tqdm_notebook(documents):\n",
    "        for sentence in razdel.sentenize(document):\n",
    "            lemmatized_tokens = [lemmatize(token) for token in tokenize(sentence.text)]\n",
    "            tokenized_sentences.append(\n",
    "                [token for token in lemmatized_tokens if token not in stopword_set]\n",
    "            )\n",
    "    return tokenized_sentences\n",
    "\n",
    "sentence_dataset = prepare_sentence_dataset(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:52:14.893616Z",
     "start_time": "2021-04-14T09:52:14.884667Z"
    }
   },
   "outputs": [],
   "source": [
    "len(sentence_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:52:14.901229Z",
     "start_time": "2021-04-14T09:52:14.895910Z"
    }
   },
   "outputs": [],
   "source": [
    "sentence_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:52:14.914569Z",
     "start_time": "2021-04-14T09:52:14.903848Z"
    }
   },
   "outputs": [],
   "source": [
    "word2vec = gensim.models.Word2Vec(\n",
    "    size=100, sg=0, window=5, min_count=5, negative=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:52:18.981500Z",
     "start_time": "2021-04-14T09:52:14.917322Z"
    }
   },
   "outputs": [],
   "source": [
    "word2vec.build_vocab(sentence_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:52:18.987651Z",
     "start_time": "2021-04-14T09:52:18.984207Z"
    }
   },
   "outputs": [],
   "source": [
    "len(word2vec.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:54:43.651306Z",
     "start_time": "2021-04-14T09:52:18.989414Z"
    }
   },
   "outputs": [],
   "source": [
    "word2vec.train(sentence_dataset, total_examples=word2vec.corpus_count, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:54:43.808690Z",
     "start_time": "2021-04-14T09:54:43.666156Z"
    }
   },
   "outputs": [],
   "source": [
    "word2vec.wv.most_similar('мама')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:54:43.971433Z",
     "start_time": "2021-04-14T09:54:43.817317Z"
    }
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "test_words = ['альтруизм', 'бедность', 'платье', 'сентябрь', 'компьютер', 'лондон']\n",
    "\n",
    "for word in test_words:\n",
    "    print(word)\n",
    "    print(\n",
    "        tabulate(word2vec.wv.most_similar(word), tablefmt='orgtbl', headers=('neighbor', 'score')),\n",
    "        end='\\n\\n'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:54:43.998090Z",
     "start_time": "2021-04-14T09:54:43.975306Z"
    }
   },
   "outputs": [],
   "source": [
    "index2word = np.array(word2vec.wv.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:54:44.018459Z",
     "start_time": "2021-04-14T09:54:44.004619Z"
    }
   },
   "outputs": [],
   "source": [
    "index2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:54:44.025856Z",
     "start_time": "2021-04-14T09:54:44.021842Z"
    }
   },
   "outputs": [],
   "source": [
    "embeddings = word2vec.wv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:54:44.038025Z",
     "start_time": "2021-04-14T09:54:44.032393Z"
    }
   },
   "outputs": [],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "обучите TSNE на выборке случайных слов для понижения размерности векторов до двух компонент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:54:44.046647Z",
     "start_time": "2021-04-14T09:54:44.041509Z"
    }
   },
   "outputs": [],
   "source": [
    "ids = np.random.randint(low=0, high=index2word.size, size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:55:03.710686Z",
     "start_time": "2021-04-14T09:54:44.050481Z"
    }
   },
   "outputs": [],
   "source": [
    "embeddings_reduced = TSNE(random_state=SEED, n_components=2).fit_transform(embeddings[ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:55:03.723018Z",
     "start_time": "2021-04-14T09:55:03.714031Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_tsne_embeddings(embeddings, annotations):\n",
    "\n",
    "    trace = plotly.graph_objs.Scattergl(\n",
    "        x = embeddings[:, 0],\n",
    "        y = embeddings[:, 1],\n",
    "        name = 'Embedding',\n",
    "        mode = 'markers',\n",
    "\n",
    "        marker = dict(\n",
    "            colorscale='Viridis',\n",
    "            size = 6,\n",
    "            line = dict(width = 0.5),\n",
    "            opacity=0.75\n",
    "        ),\n",
    "        text=annotations\n",
    "    )\n",
    "\n",
    "    layout = dict(\n",
    "        title = \"Word2Vec 2D TSNE Embeddings\",\n",
    "        yaxis = dict(zeroline = False),\n",
    "        xaxis = dict(zeroline = False),\n",
    "        hovermode = 'closest',\n",
    "        width=800,\n",
    "        height=800\n",
    "    )\n",
    "\n",
    "    return plotly.graph_objs.Figure(data=[trace], layout=layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:55:06.592419Z",
     "start_time": "2021-04-14T09:55:03.725467Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_tsne_embeddings(embeddings_reduced, index2word[ids])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T13:34:05.038696Z",
     "start_time": "2020-10-31T13:34:05.025442Z"
    }
   },
   "source": [
    "## Sentence Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "будем строить эмбеддинг предложения простым средним векторов слов. какие еще возможны варианты?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:55:06.597443Z",
     "start_time": "2021-04-14T09:55:06.594703Z"
    }
   },
   "outputs": [],
   "source": [
    "def embed_text(text, word2index, word_embeddings):\n",
    "    return np.array([\n",
    "        word_embeddings[word2index[word]] for word in text \n",
    "        if word in word2index and word not in stopword_set\n",
    "    ]).mean(0, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:55:06.612070Z",
     "start_time": "2021-04-14T09:55:06.599327Z"
    }
   },
   "outputs": [],
   "source": [
    "word2index = {word: i for i, word in enumerate(index2word)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:55:08.899879Z",
     "start_time": "2021-04-14T09:55:06.614487Z"
    }
   },
   "outputs": [],
   "source": [
    "talk2vec = np.concatenate([embed_text(doc, word2index, embeddings) for doc in cleared_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:55:08.906775Z",
     "start_time": "2021-04-14T09:55:08.902072Z"
    }
   },
   "outputs": [],
   "source": [
    "normed_talk2vec = normalize(talk2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:55:08.933800Z",
     "start_time": "2021-04-14T09:55:08.910445Z"
    }
   },
   "outputs": [],
   "source": [
    "similarities = normed_talk2vec @ normed_talk2vec.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:55:11.982170Z",
     "start_time": "2021-04-14T09:55:08.936552Z"
    }
   },
   "outputs": [],
   "source": [
    "similar_pairs = similar_pairs_from_matrix(similarities, threshold=0.96) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:55:11.999805Z",
     "start_time": "2021-04-14T09:55:11.989388Z"
    }
   },
   "outputs": [],
   "source": [
    "similar_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:55:12.022647Z",
     "start_time": "2021-04-14T09:55:12.002405Z"
    }
   },
   "outputs": [],
   "source": [
    "for pair, score in similar_pairs:\n",
    "    print(\"*\" * 10)\n",
    "    print(f\"{score:.2f}\")\n",
    "    print(\"*\" * 10)\n",
    "    print_talks(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:55:26.987515Z",
     "start_time": "2021-04-14T09:55:12.025447Z"
    }
   },
   "outputs": [],
   "source": [
    "talk2vec_reduced = TSNE(n_components=2, random_state=SEED).fit_transform(talk2vec)\n",
    "\n",
    "plot_tsne_embeddings(talk2vec_reduced, df.talk.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:55:29.004095Z",
     "start_time": "2021-04-14T09:55:26.989250Z"
    }
   },
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(cleared_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:55:29.012193Z",
     "start_time": "2021-04-14T09:55:29.008751Z"
    }
   },
   "outputs": [],
   "source": [
    "len(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:55:29.036187Z",
     "start_time": "2021-04-14T09:55:29.013882Z"
    }
   },
   "outputs": [],
   "source": [
    "_ = dictionary[0] # так надо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:55:30.410795Z",
     "start_time": "2021-04-14T09:55:29.038585Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(doc) for doc in cleared_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:55:30.424271Z",
     "start_time": "2021-04-14T09:55:30.413334Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus[59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:57:27.702878Z",
     "start_time": "2021-04-14T09:55:30.426883Z"
    }
   },
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=dictionary.id2token,\n",
    "    chunksize=200,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=400,\n",
    "    num_topics=20,\n",
    "    passes=20,\n",
    "    random_state=SEED,\n",
    "    per_word_topics=True,\n",
    "    eval_every=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:57:27.726344Z",
     "start_time": "2021-04-14T09:57:27.707778Z"
    }
   },
   "outputs": [],
   "source": [
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Матрица тем:  $$\\Theta \\left( T \\times \\vert V \\vert \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:57:27.733221Z",
     "start_time": "2021-04-14T09:57:27.728250Z"
    }
   },
   "outputs": [],
   "source": [
    "theta = lda_model.get_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:57:27.738762Z",
     "start_time": "2021-04-14T09:57:27.735438Z"
    }
   },
   "outputs": [],
   "source": [
    "theta.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Матрица документов: $$\\Phi \\left(\\vert D \\vert \\times  T \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:57:27.743680Z",
     "start_time": "2021-04-14T09:57:27.741041Z"
    }
   },
   "outputs": [],
   "source": [
    "document_topics = lda_model.get_document_topics(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:57:31.076376Z",
     "start_time": "2021-04-14T09:57:27.746146Z"
    }
   },
   "outputs": [],
   "source": [
    "phi = gensim.matutils.corpus2dense(document_topics, num_terms=lda_model.num_topics).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:57:31.083955Z",
     "start_time": "2021-04-14T09:57:31.078349Z"
    }
   },
   "outputs": [],
   "source": [
    "phi.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поиск похожих документов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:57:31.119364Z",
     "start_time": "2021-04-14T09:57:31.086481Z"
    }
   },
   "outputs": [],
   "source": [
    "similarities = cosine_similarity(phi, phi)\n",
    "\n",
    "similarities.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:57:31.473815Z",
     "start_time": "2021-04-14T09:57:31.122639Z"
    }
   },
   "outputs": [],
   "source": [
    "df[df.text.apply(lambda x: 'машинное обучение' in x.lower())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:57:31.479093Z",
     "start_time": "2021-04-14T09:57:31.476058Z"
    }
   },
   "outputs": [],
   "source": [
    "doc_id = 540\n",
    "top_k = 20\n",
    "\n",
    "sorted_doc_ids = similarities[doc_id].argsort()[::-1][:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:57:31.493846Z",
     "start_time": "2021-04-14T09:57:31.481556Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "pd.DataFrame({'neighbor': df.talk.values[sorted_doc_ids], 'similarity': similarities[doc_id, sorted_doc_ids]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Краткое описание документов (суммаризация)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:59:10.377550Z",
     "start_time": "2021-04-14T09:59:10.372143Z"
    }
   },
   "outputs": [],
   "source": [
    "def summarize(document, model, top_k):\n",
    "    tokenized_sentences = []\n",
    "    sentences = []\n",
    "    for sentence in razdel.sentenize(document):\n",
    "        sentences.append(sentence.text)\n",
    "        lemmatized_tokens = [lemmatize(token) for token in tokenize(sentence.text)]\n",
    "        tokenized_sentences.append(\n",
    "            [token for token in lemmatized_tokens if token not in stopword_set]\n",
    "        )\n",
    "    \n",
    "    tokenized_document = [token for sentence in tokenized_sentences for token in sentence]\n",
    "    bow = dictionary.doc2bow(tokenized_document)\n",
    "    document_topics = [model.get_document_topics(bow)]\n",
    "    document_vector = gensim.matutils.corpus2dense(document_topics, num_terms=model.num_topics).reshape(1, -1)\n",
    "    \n",
    "    sentence_bows = [dictionary.doc2bow(sentence) for sentence in tokenized_sentences]\n",
    "    sentence_topics = model.get_document_topics(sentence_bows)\n",
    "    sentence_vectors = gensim.matutils.corpus2dense(sentence_topics, num_terms=model.num_topics).T\n",
    "    \n",
    "    relevance = cosine_similarity(document_vector, sentence_vectors)[0]\n",
    "    most_relevant_sentences = relevance.argsort()[::-1][:top_k]\n",
    "    \n",
    "    return \" \".join([sentence for i, sentence in enumerate(sentences) if i in most_relevant_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:59:12.068893Z",
     "start_time": "2021-04-14T09:59:11.767545Z"
    }
   },
   "outputs": [],
   "source": [
    "summarize(df.text.values[540], lda_model, top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:59:19.407316Z",
     "start_time": "2021-04-14T09:59:19.402006Z"
    }
   },
   "outputs": [],
   "source": [
    "df.text.values[540]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализация тематической модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:57:32.240908Z",
     "start_time": "2021-04-14T09:49:25.654Z"
    }
   },
   "outputs": [],
   "source": [
    "vis = pyLDAvis.gensim.prepare(topic_model=lda_model, corpus=corpus, dictionary=dictionary)\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.display(vis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
